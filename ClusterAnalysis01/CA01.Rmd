---
title: "Введение в иерархический кластерный анализ: матрица расстояний, метод агломерации, дендрограмма"
author: "Алла Тамбовцева"
output:
  pdf_document:
    latex_engine: xelatex
mainfont: CMU Serif
header-includes:
- \usepackage[russian]{babel}
- \usepackage{hyperref}
- \hypersetup{colorlinks = true, urlcolor = blue, linkcolor=blue}
---

\large
Реализуем в R иерархический кластерный анализ, который мы проделали на лекции вручную. У нас есть пять наблюдений и 
две переменные, $X$ и $Y$. Запишем значения в векторы, а затем объединим их в датафрейм:

```{r}
x <- c(2, 2, 8, 10, 5)
y <- c(6, 8, 2, 3, 5)

dat <- cbind.data.frame(x, y)
dat
```

**Примечание 1:** `cbind` соответствует объединению по столбцам (от *columns*), `rbind` — объединению по строкам (от *rows*). 

**Примечание 2:** в данном случае функция `cbind()` тоже бы подошла, только стоит иметь в виду, что она создаёт матрицу, а не датафрейм. Проблема может возникнуть тогда, когда `x` и `y` являются векторами разного типа, при объединении в матрицу все элементы будут приведены к одному типу. Победит более сильный тип: например, строковый (*character*) вытеснит числовой (*numeric*), и все элементы станут текстовыми.

Добавим к нашему датафрейму названия строк. В R есть встроенный вектор `LETTERS`, содержащий заглавные буквы английского алфавита. Возьмём оттуда первые пять букв и запишем в названия строк:

```{r}
rownames(dat) <- LETTERS[1:5]
dat
```

Построим матрицу расстояний `D`, но прежде шкалируем наши данные с помощью функции `scale()`: вычтем из каждого значения в столбце `x` среднее по столбцу и поделим на стандартное отклонение по столбцу, затем проделаем то же самое для столбца `y`:

```{r}
D <- dist(scale(dat))
D
```

Матрица в R получилась довольно экономной: она показывает только расстояния между различными точками и не дублирует одни и те же расстояния, предполагая, что матрица симметричная. По умолчанию функция `dist()` считает евклидово расстояние. Запросим документацию функции через `?`:

```{r, eval=FALSE}
?dist
```

Список доступных расстояний:

* `euclidean`: евклидово расстояние;
* `maximum`: расстояние Чебышёва;
* `manhattan`: манхэттенское расстояние;
* `canberra`: [канберрское](https://en.wikipedia.org/wiki/Canberra_distance) расстояние;
* `binary`: асимметричное бинарное расстояние;
* `minkowski`: расстояние [Минковского](https://en.wikipedia.org/wiki/Minkowski_distance).

Теперь запустим иерархический кластерный анализ, выберем метод ближнего соседа, метод одиночной связи (`single`):

```{r}
hc <- hclust(D, method = "single")
hc
```

По умолчанию функция `hclust()` использует метод дальнего соседа, метод полной связи (`complete`), список основных методов такой:

* `complete`: метод полной связи;
* `single`: метод одиночной связи;
* `average`: метод средней связи;
* `median`: метод медианной связи;
* `centroid`: метод центроидной связи.

Осталось только построить дендрограмму, для этого потребуется только базовая функция `plot()`:

```{r, fig.height=3.5}
plot(hc, main = "Single linkage method")
```

Если мы определились с числом кластеров, можем выделить их на дендрограмме явно, с помощью прямоугольников:

```{r, fig.height=3.5}
plot(hc, main = "Single linkage method")
rect.hclust(hc, k = 3, border = "red")
```

**Примечание:**  функция `rect.hclust()` добавляет прямоугольники на уже существующий график, то есть накладывает ещё один слой c графическими элементами. Поэтому эта строка с кодом должна запускаться сразу после `plot()`. Если запустить её два раза с разным `k`, не перезапустив строку с `plot()`, прямоугольники тоже добавятся два раза, поэтому не забывайте обновлять саму дендрограмму.

Из объекта `hc`, который нам создала функция `hclust()`, можно извлекать отдельные элементы. Например, расстояния, при которых производилось объединение кластеров на каждой итерации алгоритма:

```{r}
hc$height
```

Расстояния отличаются от тех, которые были на лекции, так как на лекции мы пренебрегли шкалированием, ссылаясь на то, что оба показателя измерены в одних и тех же единицах измерения.
